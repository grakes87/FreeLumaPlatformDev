---
phase: 03-real-time
plan: 09
type: execute
wave: 3
depends_on: ["03-04"]
files_modified:
  - src/hooks/useVoiceRecorder.ts
  - src/components/chat/VoiceRecorder.tsx
  - src/components/chat/MediaAttachmentSheet.tsx
  - src/components/chat/VoicePlayback.tsx
autonomous: true

must_haves:
  truths:
    - "User can hold mic button to record voice message with live waveform + timer"
    - "User can tap cancel button to discard recording"
    - "Recording auto-stops at 60 seconds"
    - "Voice message uploads to B2 via presigned URL and sends as message"
    - "Voice messages play back with static proportional bars (recording=live AnalyserNode waveform, playback=static bars with progress fill — standard WhatsApp approach)"
    - "Media attachment sheet allows gallery, camera, and voice selection"
    - "Browser compatibility: graceful fallback when MediaRecorder not supported"
  artifacts:
    - path: "src/hooks/useVoiceRecorder.ts"
      provides: "MediaRecorder + AnalyserNode hook for recording with waveform"
      exports: ["useVoiceRecorder"]
    - path: "src/components/chat/VoiceRecorder.tsx"
      provides: "Recording UI with waveform, timer, and cancel"
    - path: "src/components/chat/MediaAttachmentSheet.tsx"
      provides: "Bottom sheet for Gallery/Camera/Voice attachment options"
  key_links:
    - from: "src/hooks/useVoiceRecorder.ts"
      to: "MediaRecorder API"
      via: "native browser recording"
      pattern: "new MediaRecorder"
    - from: "src/components/chat/VoiceRecorder.tsx"
      to: "/api/upload/chat-media"
      via: "upload recorded blob to B2"
      pattern: "upload.*chat-media"
---

<objective>
Implement voice message recording with live waveform visualization, media attachment bottom sheet, and voice playback component. Uses native MediaRecorder API with cross-browser MIME type detection.

Purpose: Enable WhatsApp-style voice messaging and rich media attachment for chat.
Output: Voice recorder hook, 3 components.
</objective>

<execution_context>
@/Users/admin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/admin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/03-real-time/03-RESEARCH.md (Voice Recording code example, Pitfall 5)
@.planning/phases/03-real-time/03-CONTEXT.md (voice message decisions)
@.planning/phases/03-real-time/03-04-SUMMARY.md
@src/lib/storage/presign.ts (presigned URL pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create voice recorder hook and recording UI</name>
  <files>
    src/hooks/useVoiceRecorder.ts
    src/components/chat/VoiceRecorder.tsx
  </files>
  <action>
    1. Create `src/hooks/useVoiceRecorder.ts`:
       - Follow the research code example closely (src/hooks/useVoiceRecorder.ts in RESEARCH.md)
       - MIME type detection: try audio/webm;codecs=opus, audio/mp4;codecs=aac, audio/webm
       - startRecording(): getUserMedia, setup AudioContext + AnalyserNode for waveform, create MediaRecorder
       - Collect chunks every 100ms via ondataavailable
       - Track duration with setInterval (update every second)
       - Track audioLevel (0-1) from AnalyserNode for waveform visualization
       - Auto-stop at 60 seconds (MAX_DURATION_MS = 60000)
       - stopRecording(): returns Promise<Blob | null> — stops recorder, returns blob
       - cancelRecording(): stops everything, discards chunks
       - Cleanup on unmount: cancelAnimationFrame, clearInterval, close AudioContext, stop media tracks
       - Expose: { isRecording, duration, audioLevel, isSupported, startRecording, stopRecording, cancelRecording }

    2. Create `src/components/chat/VoiceRecorder.tsx`:
       - Shown when user is recording (replaces normal input area)
       - Layout: [Cancel button] [Waveform bars] [Timer] [Send button]
       - Waveform: animated vertical bars whose height scales with audioLevel (6-10 bars)
       - Timer: MM:SS format, counting up
       - Cancel button: red X icon, calls cancelRecording()
       - Send button: blue send icon, calls stopRecording() then uploads
       - Upload flow:
         - Get presigned URL from POST /api/upload/chat-media with content type from MIME
         - PUT blob to presigned URL
         - Send message via POST /api/chat/conversations/[id]/messages with type: 'voice', media: [{url, type: 'voice', duration}]
       - Visual: slide-in animation from bottom, red recording indicator dot
       - Accessibility: aria-label for buttons
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - useVoiceRecorder handles MediaRecorder lifecycle
    - VoiceRecorder shows waveform and timer during recording
    - Cancel discards, send uploads and creates message
  </verify>
  <done>Voice recording with waveform visualization, upload to B2, and message creation</done>
</task>

<task type="auto">
  <name>Task 2: Create media attachment sheet and voice playback</name>
  <files>
    src/components/chat/MediaAttachmentSheet.tsx
    src/components/chat/VoicePlayback.tsx
  </files>
  <action>
    1. Create `src/components/chat/MediaAttachmentSheet.tsx`:
       - Bottom sheet overlay (similar to comment bottom sheets in Phase 2)
       - Three options with icons:
         - Gallery (Image icon): opens file input accept="image/*,video/*" with multiple
         - Camera (Camera icon): opens file input with capture="environment"
         - Voice (Mic icon): triggers voice recording mode (callback to parent)
       - Up to 10 media attachments per message
       - Selected media: show thumbnail previews with X to remove
       - Send button to attach media to message
       - Upload flow for gallery/camera: get presigned URLs, upload each file, then send message with media array
       - Use existing uploadWithProgress utility if available, otherwise basic fetch PUT
       - Close on tap outside or swipe down

    2. Create `src/components/chat/VoicePlayback.tsx`:
       - Component for rendering voice message in MessageBubble
       - Props: mediaUrl, duration (seconds)
       - Layout: [Play/Pause button] [Waveform visualization] [Duration]
       - Play: HTML5 Audio element, play/pause toggle
       - Waveform: static proportional bars based on duration (recording uses live AnalyserNode waveform; playback uses static bars — this is the standard WhatsApp approach since analyzing actual audio requires full download/decode)
       - Progress: as audio plays, fill waveform bars proportionally (bars transition from gray to accent color left-to-right)
       - Duration display: "0:42" format, shows remaining time during playback
       - Normal speed only (no 1x/1.5x/2x per CONTEXT)
       - Handle loading state (show spinner while audio buffers)
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - MediaAttachmentSheet shows Gallery/Camera/Voice options
    - VoicePlayback plays audio with progress visualization
    - File selection limited to 10 items
  </verify>
  <done>Media attachment bottom sheet with gallery/camera/voice options, voice playback with progress waveform</done>
</task>

</tasks>

<verification>
- Voice recording works with live waveform visualization
- Auto-stop at 60 seconds
- Cancel discards recording
- Recorded voice uploads to B2 and sends as message
- Media attachment sheet offers gallery, camera, and voice options
- Voice playback shows play/pause with progress
- Graceful fallback when MediaRecorder not supported
</verification>

<success_criteria>
Users can record voice messages (WhatsApp-style hold-to-record), attach images/videos from gallery or camera, and play back voice messages with visual progress.
</success_criteria>

<output>
After completion, create `.planning/phases/03-real-time/03-09-SUMMARY.md`
</output>
